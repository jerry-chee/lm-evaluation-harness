#!/bin/bash
#SBATCH --job-name=1_lm_eval
#SBATCH -N 1
#SBATCH --cpus-per-task 16
#SBATCH --mem=40G
#SBATCH --partition=gpu
#SBATCH --gres=gpu:4
#SBATCH --time 24:00:00
#SBATCH --output "slurm/logs/lm_eval_1_%j.out"                  # Name of stdout output     log file (%j expands to jobID)
#SBATCH --error "slurm/logs/lm_eval_1_%j.err"                  # Name of stderr output     log file (%j expands to jobID)

# evaluates model with lm-eval. for now, only run one at a time bc of offload folder

source ~/.bashrc
source ~/anaconda3/etc/profile.d/conda.sh
conda activate lm_eval

for model in "opt-30b_W8A8_per_tensor" "opt-30b_W4A8_per_tensor" "opt-30b_W4A4_per_tensor" "opt-66b_W8A8_per_tensor" "opt-66b_W4A8_per_tensor" "opt-66b_W4A4_per_tensor"
do
WPATH=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/${model}
python main.py \
    --model gpt2 \
    --model_args pretrained=${WPATH} \
    --tasks lambada_openai,hellaswag,piqa,winogrande,openbookqa,rte,copa,wikitext
done