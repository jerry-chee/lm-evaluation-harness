#!/bin/bash
#SBATCH --job-name=1_lm_eval
#SBATCH -N 1
#SBATCH --cpus-per-task 32
#SBATCH --mem=40G
#SBATCH --partition=gpu
#SBATCH --gres=gpu:1
#SBATCH --time 24:00:00
#SBATCH --output "slurm/logs/lm_eval_1_%j.out"                  # Name of stdout output     log file (%j expands to jobID)
#SBATCH --error "slurm/logs/lm_eval_1_%j.err"                  # Name of stderr output     log file (%j expands to jobID)

# evaluates model with lm-eval

source ~/.bashrc
source ~/anaconda3/etc/profile.d/conda.sh
conda activate lm_eval

# for model in "opt-30b" "opt-66b"
for model in "opt-6.7b"
do
for task in "lambada_openai" "hellaswag" "piqa" "winogrande" "openbookqa" "rte" "copa" "wikitext"
do
WPATH=facebook/${model}
python main.py \
    --model gpt2 \
    --model_args pretrained=${WPATH} \
    --tasks ${task} \
    --offload_folder lm_offload/tmp1 \
    --output_path slurm/output/${model}_${task}
done
done