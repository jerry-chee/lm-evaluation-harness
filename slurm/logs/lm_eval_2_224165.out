opt-6.7b_W8A8_per_tensor
adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['lambada_openai']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
bootstrapping for stddev: perplexity
{
  "results": {
    "lambada_openai": {
      "ppl": 3.940755144766027,
      "ppl_stderr": 0.08570429220235497,
      "acc": 0.6928003104987386,
      "acc_stderr": 0.006427269282158888
    }
  },
  "versions": {
    "lambada_openai": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W8A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W8A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|     Task     |Version|Metric|Value |   |Stderr|
|--------------|------:|------|-----:|---|-----:|
|lambada_openai|      0|ppl   |3.9408|±  |0.0857|
|              |       |acc   |0.6928|±  |0.0064|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['hellaswag']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "hellaswag": {
      "acc": 0.50318661621191,
      "acc_stderr": 0.004989680072717476,
      "acc_norm": 0.6694881497709619,
      "acc_norm_stderr": 0.004694360968929397
    }
  },
  "versions": {
    "hellaswag": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W8A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W8A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|  Task   |Version| Metric |Value |   |Stderr|
|---------|------:|--------|-----:|---|-----:|
|hellaswag|      0|acc     |0.5032|±  |0.0050|
|         |       |acc_norm|0.6695|±  |0.0047|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['piqa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "piqa": {
      "acc": 0.7589771490750816,
      "acc_stderr": 0.009979042717267315,
      "acc_norm": 0.764961915125136,
      "acc_norm_stderr": 0.009893146688805308
    }
  },
  "versions": {
    "piqa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W8A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W8A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version| Metric |Value|   |Stderr|
|----|------:|--------|----:|---|-----:|
|piqa|      0|acc     |0.759|±  |0.0100|
|    |       |acc_norm|0.765|±  |0.0099|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['winogrande']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "winogrande": {
      "acc": 0.6614048934490924,
      "acc_stderr": 0.013300169865842421
    }
  },
  "versions": {
    "winogrande": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W8A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W8A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|   Task   |Version|Metric|Value |   |Stderr|
|----------|------:|------|-----:|---|-----:|
|winogrande|      0|acc   |0.6614|±  |0.0133|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['openbookqa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "openbookqa": {
      "acc": 0.274,
      "acc_stderr": 0.01996610354027947,
      "acc_norm": 0.38,
      "acc_norm_stderr": 0.021728881438701702
    }
  },
  "versions": {
    "openbookqa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W8A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W8A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|   Task   |Version| Metric |Value|   |Stderr|
|----------|------:|--------|----:|---|-----:|
|openbookqa|      0|acc     |0.274|±  |0.0200|
|          |       |acc_norm|0.380|±  |0.0217|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['rte']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "rte": {
      "acc": 0.5523465703971119,
      "acc_stderr": 0.029931070362939526
    }
  },
  "versions": {
    "rte": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W8A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W8A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version|Metric|Value |   |Stderr|
|----|------:|------|-----:|---|-----:|
|rte |      0|acc   |0.5523|±  |0.0299|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['copa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "copa": {
      "acc": 0.83,
      "acc_stderr": 0.0377525168068637
    }
  },
  "versions": {
    "copa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W8A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W8A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version|Metric|Value|   |Stderr|
|----|------:|------|----:|---|-----:|
|copa|      0|acc   | 0.83|±  |0.0378|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['wikitext']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood_rolling requests
{
  "results": {
    "wikitext": {
      "word_perplexity": 12.411114639551851,
      "byte_perplexity": 1.6015779644260035,
      "bits_per_byte": 0.6794940298659492
    }
  },
  "versions": {
    "wikitext": 1
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W8A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W8A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|  Task  |Version|    Metric     | Value |   |Stderr|
|--------|------:|---------------|------:|---|------|
|wikitext|      1|word_perplexity|12.4111|   |      |
|        |       |byte_perplexity| 1.6016|   |      |
|        |       |bits_per_byte  | 0.6795|   |      |

