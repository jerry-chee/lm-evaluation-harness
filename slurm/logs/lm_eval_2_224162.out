opt-6.7b_W2A8_per_tensor
adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['lambada_openai']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
bootstrapping for stddev: perplexity
{
  "results": {
    "lambada_openai": {
      "ppl": 5505453.791910716,
      "ppl_stderr": 649686.410473123,
      "acc": 0.0,
      "acc_stderr": 0.0
    }
  },
  "versions": {
    "lambada_openai": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W2A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W2A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|     Task     |Version|Metric|   Value    |   |  Stderr   |
|--------------|------:|------|-----------:|---|----------:|
|lambada_openai|      0|ppl   |5505453.7919|±  |649686.4105|
|              |       |acc   |      0.0000|±  |     0.0000|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['hellaswag']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "hellaswag": {
      "acc": 0.2546305516829317,
      "acc_stderr": 0.004347629889040943,
      "acc_norm": 0.25672176857199763,
      "acc_norm_stderr": 0.004359318206428672
    }
  },
  "versions": {
    "hellaswag": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W2A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W2A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|  Task   |Version| Metric |Value |   |Stderr|
|---------|------:|--------|-----:|---|-----:|
|hellaswag|      0|acc     |0.2546|±  |0.0043|
|         |       |acc_norm|0.2567|±  |0.0044|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['piqa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "piqa": {
      "acc": 0.5261153427638737,
      "acc_stderr": 0.011649900854263422,
      "acc_norm": 0.5087051142546246,
      "acc_norm_stderr": 0.011664055982032838
    }
  },
  "versions": {
    "piqa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W2A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W2A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version| Metric |Value |   |Stderr|
|----|------:|--------|-----:|---|-----:|
|piqa|      0|acc     |0.5261|±  |0.0116|
|    |       |acc_norm|0.5087|±  |0.0117|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['winogrande']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "winogrande": {
      "acc": 0.494869771112865,
      "acc_stderr": 0.014051745961790516
    }
  },
  "versions": {
    "winogrande": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W2A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W2A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|   Task   |Version|Metric|Value |   |Stderr|
|----------|------:|------|-----:|---|-----:|
|winogrande|      0|acc   |0.4949|±  |0.0141|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['openbookqa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "openbookqa": {
      "acc": 0.13,
      "acc_stderr": 0.015055009352810985,
      "acc_norm": 0.282,
      "acc_norm_stderr": 0.020143572847290788
    }
  },
  "versions": {
    "openbookqa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W2A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W2A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|   Task   |Version| Metric |Value|   |Stderr|
|----------|------:|--------|----:|---|-----:|
|openbookqa|      0|acc     |0.130|±  |0.0151|
|          |       |acc_norm|0.282|±  |0.0201|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['rte']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "rte": {
      "acc": 0.5270758122743683,
      "acc_stderr": 0.030052303463143706
    }
  },
  "versions": {
    "rte": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W2A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W2A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version|Metric|Value |   |Stderr|
|----|------:|------|-----:|---|-----:|
|rte |      0|acc   |0.5271|±  |0.0301|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['copa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "copa": {
      "acc": 0.57,
      "acc_stderr": 0.04975698519562428
    }
  },
  "versions": {
    "copa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W2A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W2A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version|Metric|Value|   |Stderr|
|----|------:|------|----:|---|-----:|
|copa|      0|acc   | 0.57|±  |0.0498|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['wikitext']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood_rolling requests
{
  "results": {
    "wikitext": {
      "word_perplexity": 127989.21034346838,
      "byte_perplexity": 9.017101278919382,
      "bits_per_byte": 3.1726637258705184
    }
  },
  "versions": {
    "wikitext": 1
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W2A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W2A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|  Task  |Version|    Metric     |   Value   |   |Stderr|
|--------|------:|---------------|----------:|---|------|
|wikitext|      1|word_perplexity|127989.2103|   |      |
|        |       |byte_perplexity|     9.0171|   |      |
|        |       |bits_per_byte  |     3.1727|   |      |

