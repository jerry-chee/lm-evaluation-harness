opt-13b_W2A4_per_tensor
adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['lambada_openai']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
bootstrapping for stddev: perplexity
{
  "results": {
    "lambada_openai": {
      "ppl": 4089495.023024487,
      "ppl_stderr": 403365.8021696489,
      "acc": 0.0,
      "acc_stderr": 0.0
    }
  },
  "versions": {
    "lambada_openai": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W2A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W2A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|     Task     |Version|Metric|   Value   |   |  Stderr   |
|--------------|------:|------|----------:|---|----------:|
|lambada_openai|      0|ppl   |4089495.023|±  |403365.8022|
|              |       |acc   |      0.000|±  |     0.0000|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['hellaswag']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "hellaswag": {
      "acc": 0.26110336586337385,
      "acc_stderr": 0.004383384784038474,
      "acc_norm": 0.25692093208524197,
      "acc_norm_stderr": 0.004360424536145123
    }
  },
  "versions": {
    "hellaswag": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W2A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W2A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|  Task   |Version| Metric |Value |   |Stderr|
|---------|------:|--------|-----:|---|-----:|
|hellaswag|      0|acc     |0.2611|±  |0.0044|
|         |       |acc_norm|0.2569|±  |0.0044|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['piqa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "piqa": {
      "acc": 0.5125136017410229,
      "acc_stderr": 0.011662170084916887,
      "acc_norm": 0.49455930359085964,
      "acc_norm_stderr": 0.011665133500637064
    }
  },
  "versions": {
    "piqa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W2A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W2A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version| Metric |Value |   |Stderr|
|----|------:|--------|-----:|---|-----:|
|piqa|      0|acc     |0.5125|±  |0.0117|
|    |       |acc_norm|0.4946|±  |0.0117|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['winogrande']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "winogrande": {
      "acc": 0.5027624309392266,
      "acc_stderr": 0.014052271211616441
    }
  },
  "versions": {
    "winogrande": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W2A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W2A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|   Task   |Version|Metric|Value |   |Stderr|
|----------|------:|------|-----:|---|-----:|
|winogrande|      0|acc   |0.5028|±  |0.0141|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['openbookqa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "openbookqa": {
      "acc": 0.108,
      "acc_stderr": 0.013894535480989179,
      "acc_norm": 0.258,
      "acc_norm_stderr": 0.019586711785215837
    }
  },
  "versions": {
    "openbookqa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W2A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W2A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|   Task   |Version| Metric |Value|   |Stderr|
|----------|------:|--------|----:|---|-----:|
|openbookqa|      0|acc     |0.108|±  |0.0139|
|          |       |acc_norm|0.258|±  |0.0196|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['rte']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "rte": {
      "acc": 0.5270758122743683,
      "acc_stderr": 0.030052303463143706
    }
  },
  "versions": {
    "rte": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W2A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W2A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version|Metric|Value |   |Stderr|
|----|------:|------|-----:|---|-----:|
|rte |      0|acc   |0.5271|±  |0.0301|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['copa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "copa": {
      "acc": 0.53,
      "acc_stderr": 0.050161355804659205
    }
  },
  "versions": {
    "copa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W2A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W2A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version|Metric|Value|   |Stderr|
|----|------:|------|----:|---|-----:|
|copa|      0|acc   | 0.53|±  |0.0502|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['wikitext']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood_rolling requests
opt-13b_W3A4_per_tensor
adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['lambada_openai']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
bootstrapping for stddev: perplexity
{
  "results": {
    "lambada_openai": {
      "ppl": 33903912.2493959,
      "ppl_stderr": 3619691.339241451,
      "acc": 0.0,
      "acc_stderr": 0.0
    }
  },
  "versions": {
    "lambada_openai": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W3A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W3A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|     Task     |Version|Metric|    Value    |   |   Stderr   |
|--------------|------:|------|------------:|---|-----------:|
|lambada_openai|      0|ppl   |33903912.2494|±  |3619691.3392|
|              |       |acc   |       0.0000|±  |      0.0000|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['hellaswag']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "hellaswag": {
      "acc": 0.2559251145190201,
      "acc_stderr": 0.004354881005789729,
      "acc_norm": 0.2568213503286198,
      "acc_norm_stderr": 0.004359871519639543
    }
  },
  "versions": {
    "hellaswag": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W3A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W3A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|  Task   |Version| Metric |Value |   |Stderr|
|---------|------:|--------|-----:|---|-----:|
|hellaswag|      0|acc     |0.2559|±  |0.0044|
|         |       |acc_norm|0.2568|±  |0.0044|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['piqa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "piqa": {
      "acc": 0.5217627856365615,
      "acc_stderr": 0.01165476861856007,
      "acc_norm": 0.4929270946681175,
      "acc_norm_stderr": 0.011664656918145945
    }
  },
  "versions": {
    "piqa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W3A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W3A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version| Metric |Value |   |Stderr|
|----|------:|--------|-----:|---|-----:|
|piqa|      0|acc     |0.5218|±  |0.0117|
|    |       |acc_norm|0.4929|±  |0.0117|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['winogrande']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "winogrande": {
      "acc": 0.48855564325177586,
      "acc_stderr": 0.014048804199859325
    }
  },
  "versions": {
    "winogrande": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W3A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W3A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|   Task   |Version|Metric|Value |   |Stderr|
|----------|------:|------|-----:|---|-----:|
|winogrande|      0|acc   |0.4886|±  | 0.014|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['openbookqa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "openbookqa": {
      "acc": 0.134,
      "acc_stderr": 0.01524969200385449,
      "acc_norm": 0.266,
      "acc_norm_stderr": 0.01978055967565549
    }
  },
  "versions": {
    "openbookqa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W3A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W3A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|   Task   |Version| Metric |Value|   |Stderr|
|----------|------:|--------|----:|---|-----:|
|openbookqa|      0|acc     |0.134|±  |0.0152|
|          |       |acc_norm|0.266|±  |0.0198|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['rte']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "rte": {
      "acc": 0.5270758122743683,
      "acc_stderr": 0.030052303463143706
    }
  },
  "versions": {
    "rte": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W3A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W3A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version|Metric|Value |   |Stderr|
|----|------:|------|-----:|---|-----:|
|rte |      0|acc   |0.5271|±  |0.0301|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['copa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "copa": {
      "acc": 0.57,
      "acc_stderr": 0.04975698519562428
    }
  },
  "versions": {
    "copa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W3A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W3A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version|Metric|Value|   |Stderr|
|----|------:|------|----:|---|-----:|
|copa|      0|acc   | 0.57|±  |0.0498|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['wikitext']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood_rolling requests
opt-13b_W4A4_per_tensor
adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['lambada_openai']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
bootstrapping for stddev: perplexity
{
  "results": {
    "lambada_openai": {
      "ppl": 1070490618.1323409,
      "ppl_stderr": 129961938.85140474,
      "acc": 0.0,
      "acc_stderr": 0.0
    }
  },
  "versions": {
    "lambada_openai": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W4A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W4A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|     Task     |Version|Metric|     Value     |   |    Stderr    |
|--------------|------:|------|--------------:|---|-------------:|
|lambada_openai|      0|ppl   |1070490618.1323|±  |129961938.8514|
|              |       |acc   |         0.0000|±  |        0.0000|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['hellaswag']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "hellaswag": {
      "acc": 0.2599083847839076,
      "acc_stderr": 0.004376877619234116,
      "acc_norm": 0.25960963951404104,
      "acc_norm_stderr": 0.004375244237045148
    }
  },
  "versions": {
    "hellaswag": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W4A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W4A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|  Task   |Version| Metric |Value |   |Stderr|
|---------|------:|--------|-----:|---|-----:|
|hellaswag|      0|acc     |0.2599|±  |0.0044|
|         |       |acc_norm|0.2596|±  |0.0044|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['piqa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "piqa": {
      "acc": 0.5184983677910773,
      "acc_stderr": 0.011657837583818149,
      "acc_norm": 0.499455930359086,
      "acc_norm_stderr": 0.011665817258899171
    }
  },
  "versions": {
    "piqa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W4A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W4A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version| Metric |Value |   |Stderr|
|----|------:|--------|-----:|---|-----:|
|piqa|      0|acc     |0.5185|±  |0.0117|
|    |       |acc_norm|0.4995|±  |0.0117|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['winogrande']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "winogrande": {
      "acc": 0.494869771112865,
      "acc_stderr": 0.014051745961790516
    }
  },
  "versions": {
    "winogrande": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W4A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W4A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|   Task   |Version|Metric|Value |   |Stderr|
|----------|------:|------|-----:|---|-----:|
|winogrande|      0|acc   |0.4949|±  |0.0141|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['openbookqa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "openbookqa": {
      "acc": 0.122,
      "acc_stderr": 0.01465132494504479,
      "acc_norm": 0.24,
      "acc_norm_stderr": 0.019118866653759746
    }
  },
  "versions": {
    "openbookqa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W4A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W4A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|   Task   |Version| Metric |Value|   |Stderr|
|----------|------:|--------|----:|---|-----:|
|openbookqa|      0|acc     |0.122|±  |0.0147|
|          |       |acc_norm|0.240|±  |0.0191|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['rte']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "rte": {
      "acc": 0.5270758122743683,
      "acc_stderr": 0.030052303463143706
    }
  },
  "versions": {
    "rte": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W4A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W4A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version|Metric|Value |   |Stderr|
|----|------:|------|-----:|---|-----:|
|rte |      0|acc   |0.5271|±  |0.0301|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['copa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "copa": {
      "acc": 0.62,
      "acc_stderr": 0.048783173121456316
    }
  },
  "versions": {
    "copa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W4A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W4A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version|Metric|Value|   |Stderr|
|----|------:|------|----:|---|-----:|
|copa|      0|acc   | 0.62|±  |0.0488|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['wikitext']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood_rolling requests
opt-13b_W8A4_per_tensor
adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['lambada_openai']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
bootstrapping for stddev: perplexity
{
  "results": {
    "lambada_openai": {
      "ppl": 11316402.139942221,
      "ppl_stderr": 1132229.7759178022,
      "acc": 0.0,
      "acc_stderr": 0.0
    }
  },
  "versions": {
    "lambada_openai": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W8A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W8A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|     Task     |Version|Metric|    Value    |   |   Stderr   |
|--------------|------:|------|------------:|---|-----------:|
|lambada_openai|      0|ppl   |11316402.1399|±  |1132229.7759|
|              |       |acc   |       0.0000|±  |      0.0000|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['hellaswag']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "hellaswag": {
      "acc": 0.2574188408683529,
      "acc_stderr": 0.004363185172047171,
      "acc_norm": 0.2591117307309301,
      "acc_norm_stderr": 0.004372516060164739
    }
  },
  "versions": {
    "hellaswag": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W8A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W8A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|  Task   |Version| Metric |Value |   |Stderr|
|---------|------:|--------|-----:|---|-----:|
|hellaswag|      0|acc     |0.2574|±  |0.0044|
|         |       |acc_norm|0.2591|±  |0.0044|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['piqa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "piqa": {
      "acc": 0.5119695321001088,
      "acc_stderr": 0.011662480968070052,
      "acc_norm": 0.4912948857453754,
      "acc_norm_stderr": 0.011664055982032843
    }
  },
  "versions": {
    "piqa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W8A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W8A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version| Metric |Value |   |Stderr|
|----|------:|--------|-----:|---|-----:|
|piqa|      0|acc     |0.5120|±  |0.0117|
|    |       |acc_norm|0.4913|±  |0.0117|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['winogrande']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "winogrande": {
      "acc": 0.5082872928176796,
      "acc_stderr": 0.014050555322824197
    }
  },
  "versions": {
    "winogrande": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W8A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W8A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|   Task   |Version|Metric|Value |   |Stderr|
|----------|------:|------|-----:|---|-----:|
|winogrande|      0|acc   |0.5083|±  |0.0141|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['openbookqa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "openbookqa": {
      "acc": 0.132,
      "acc_stderr": 0.015152927850580157,
      "acc_norm": 0.26,
      "acc_norm_stderr": 0.019635965529725512
    }
  },
  "versions": {
    "openbookqa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W8A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W8A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|   Task   |Version| Metric |Value|   |Stderr|
|----------|------:|--------|----:|---|-----:|
|openbookqa|      0|acc     |0.132|±  |0.0152|
|          |       |acc_norm|0.260|±  |0.0196|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['rte']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "rte": {
      "acc": 0.5487364620938628,
      "acc_stderr": 0.029953149241808943
    }
  },
  "versions": {
    "rte": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W8A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W8A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version|Metric|Value |   |Stderr|
|----|------:|------|-----:|---|-----:|
|rte |      0|acc   |0.5487|±  |  0.03|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['copa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "copa": {
      "acc": 0.56,
      "acc_stderr": 0.049888765156985884
    }
  },
  "versions": {
    "copa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W8A4_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-13b_W8A4_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version|Metric|Value|   |Stderr|
|----|------:|------|----:|---|-----:|
|copa|      0|acc   | 0.56|±  |0.0499|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['wikitext']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A4 with quantize_outputTrue
Running loglikelihood_rolling requests
