opt-6.7b_W4A8_per_tensor
adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['lambada_openai']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
bootstrapping for stddev: perplexity
{
  "results": {
    "lambada_openai": {
      "ppl": 943812769.6595309,
      "ppl_stderr": 116493178.33938606,
      "acc": 0.0,
      "acc_stderr": 0.0
    }
  },
  "versions": {
    "lambada_openai": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W4A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W4A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|     Task     |Version|Metric|    Value     |   |    Stderr    |
|--------------|------:|------|-------------:|---|-------------:|
|lambada_openai|      0|ppl   |943812769.6595|±  |116493178.3394|
|              |       |acc   |        0.0000|±  |        0.0000|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['hellaswag']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "hellaswag": {
      "acc": 0.26110336586337385,
      "acc_stderr": 0.004383384784038475,
      "acc_norm": 0.25433180641306513,
      "acc_norm_stderr": 0.004345949382382368
    }
  },
  "versions": {
    "hellaswag": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W4A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W4A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|  Task   |Version| Metric |Value |   |Stderr|
|---------|------:|--------|-----:|---|-----:|
|hellaswag|      0|acc     |0.2611|±  |0.0044|
|         |       |acc_norm|0.2543|±  |0.0043|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['piqa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "piqa": {
      "acc": 0.5179542981501633,
      "acc_stderr": 0.011658300623287153,
      "acc_norm": 0.48748639825897716,
      "acc_norm_stderr": 0.01166217008491689
    }
  },
  "versions": {
    "piqa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W4A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W4A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version| Metric |Value |   |Stderr|
|----|------:|--------|-----:|---|-----:|
|piqa|      0|acc     |0.5180|±  |0.0117|
|    |       |acc_norm|0.4875|±  |0.0117|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['winogrande']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "winogrande": {
      "acc": 0.48303078137332284,
      "acc_stderr": 0.014044390401612976
    }
  },
  "versions": {
    "winogrande": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W4A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W4A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|   Task   |Version|Metric|Value|   |Stderr|
|----------|------:|------|----:|---|-----:|
|winogrande|      0|acc   |0.483|±  | 0.014|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['openbookqa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "openbookqa": {
      "acc": 0.122,
      "acc_stderr": 0.01465132494504481,
      "acc_norm": 0.254,
      "acc_norm_stderr": 0.019486596801643375
    }
  },
  "versions": {
    "openbookqa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W4A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W4A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|   Task   |Version| Metric |Value|   |Stderr|
|----------|------:|--------|----:|---|-----:|
|openbookqa|      0|acc     |0.122|±  |0.0147|
|          |       |acc_norm|0.254|±  |0.0195|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['rte']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "rte": {
      "acc": 0.5270758122743683,
      "acc_stderr": 0.030052303463143706
    }
  },
  "versions": {
    "rte": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W4A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W4A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version|Metric|Value |   |Stderr|
|----|------:|------|-----:|---|-----:|
|rte |      0|acc   |0.5271|±  |0.0301|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['copa']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood requests
{
  "results": {
    "copa": {
      "acc": 0.53,
      "acc_stderr": 0.05016135580465919
    }
  },
  "versions": {
    "copa": 0
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W4A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W4A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|Task|Version|Metric|Value|   |Stderr|
|----|------:|------|----:|---|-----:|
|copa|      0|acc   | 0.53|±  |0.0502|

adding parentpath /home/jc3464/QuantHerd/quant-balance-herd-smooth/
Selected Tasks: ['wikitext']
Using device 'cuda'
replacing linear layers with WALinear with copy_dataFalse
quantizingA(per_tensor) to A8 with quantize_outputTrue
Running loglikelihood_rolling requests
{
  "results": {
    "wikitext": {
      "word_perplexity": 205691.5615211262,
      "byte_perplexity": 9.8536706029079,
      "bits_per_byte": 3.300661244788498
    }
  },
  "versions": {
    "wikitext": 1
  },
  "config": {
    "model": "gpt2",
    "model_args": "pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W4A8_per_tensor",
    "num_fewshot": 0,
    "batch_size": null,
    "device": null,
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
gpt2 (pretrained=/home/jc3464/QuantHerd/quant-balance-herd-smooth/checkpoints_smoothquant/opt-6.7b_W4A8_per_tensor), limit: None, provide_description: False, num_fewshot: 0, batch_size: None
|  Task  |Version|    Metric     |   Value   |   |Stderr|
|--------|------:|---------------|----------:|---|------|
|wikitext|      1|word_perplexity|205691.5615|   |      |
|        |       |byte_perplexity|     9.8537|   |      |
|        |       |bits_per_byte  |     3.3007|   |      |

